# -*- coding: utf-8 -*-
"""Image to text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bPp0wB_xYZdQiLk50hb8KcCMeIUqZDVJ
"""

!pip install opencv-python pytesseract tensorflow==2.12.0

import cv2
import pytesseract

import cv2
import pytesseract
from google.colab import drive
drive.mount('/content/drive')

!wget https://pjreddie.com/media/files/yolov3.weights  # Download weights
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg

import cv2
import os
from google.colab import drive

drive.mount('/content/drive')

def resize_images(image_folder, target_size=(608, 608), max_images=100):
    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]
    image_files = image_files[:max_images]  # Limit to max_images

    for filename in image_files:
        if filename.endswith(('.jpg', '.png', '.jpeg')):  # Adjust file extensions as needed
            image_path = os.path.join(image_folder, filename)
            img = cv2.imread(image_path)
            resized_img = cv2.resize(img, target_size)
            cv2.imwrite(image_path, resized_img)  # Overwrite original with resized image


dataset_folder = '/content/drive/MyDrive/Dataset_OCR'  # Path to your Dataset_OCR folder
image_folder = dataset_folder  # Assuming images are directly in Dataset_OCR


resize_images(image_folder)

print(f"Resized {len(os.listdir(image_folder))} images in {image_folder}")

import cv2
import os

def resize_and_save_gray(image_folder, output_folder, target_size=(608, 608), max_images=100):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]
    image_files = image_files[:max_images]

    for filename in image_files:
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            img = cv2.imread(image_path)

            # Convert to grayscale
            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Resize the grayscale image
            resized_gray_img = cv2.resize(gray_img, target_size)

            # Construct the output path
            output_path = os.path.join(output_folder, filename)

            # Save the resized grayscale image
            cv2.imwrite(output_path, resized_gray_img)

dataset_folder = '/content/drive/MyDrive/Dataset_OCR/'
output_folder = '/content/drive/MyDrive/Gray_Size' # Output folder

resize_and_save_gray(dataset_folder, output_folder)

print(f"Resized grayscale images saved to: {output_folder}")

import torch
import torchvision
import os

# Define paths
drive_path = '/content/drive/MyDrive/'
model_path = os.path.join(drive_path, 'Data Image')
dataset_path = os.path.join(drive_path, 'Dataset_OCR')
validation_path = os.path.join(drive_path, 'validation_results')


# Check if CUDA is available
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

# Create directories if they don't exist
os.makedirs(model_path, exist_ok=True)
os.makedirs(validation_path, exist_ok=True)

print("Trained weights saved to:", model_path)

import pandas as pd

def extract_features_and_save_csv(image_folder, output_csv_path, num_images=80):
    results = []
    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))][:num_images]

    for filename in image_files:
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            img = cv2.imread(image_path)

            # Perform OCR (replace with your actual OCR logic using YOLO and Tesseract)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            text = pytesseract.image_to_string(gray)

            # Placeholder for feature extraction (replace with your actual logic)
            test_name = "Test Name Placeholder"  # Replace with actual extraction
            technology = "Technology Placeholder"
            value = "Value Placeholder"
            units = "Units Placeholder"
            reference_range = "Reference Range Placeholder"

            results.append({
                'filename': filename,
                'test_name': test_name,
                'technology': technology,
                'value': value,
                'units': units,
                'reference_range': reference_range,
                'extracted_text': text # Adding extracted text
            })

    df = pd.DataFrame(results)
    df.to_csv(output_csv_path, index=False)



gray_images_folder = '/content/drive/MyDrive/Gray_Size'
output_csv_path = '/content/drive/MyDrive/extracted_features.csv'  # New CSV file name
extract_features_and_save_csv(gray_images_folder, output_csv_path)
print(f"Extracted features saved to {output_csv_path}")

import cv2
import pytesseract
import os
from google.colab.patches import cv2_imshow
import pandas as pd

drive.mount('/content/drive')

image_folder='/content/drive/MyDrive/Gray_Size'
output_folder='/content/drive/MyDrive/Train_Model/output_folder'

def draw_bounding_boxes(image_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for filename in os.listdir(image_folder):
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            img = cv2.imread(image_path)

            # Convert the image to grayscale
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Perform OCR using pytesseract
            data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)

            n_boxes = len(data['level'])
            for i in range(n_boxes):
                if int(data['conf'][i]) > 60:  # Adjust confidence threshold as needed
                    (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])
                    img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)

            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, img)


gray_images_folder = '/content/drive/MyDrive/Gray_Size'
output_folder_with_boxes = '/content/drive/MyDrive/Train_Model/Gray_Size_Boxes'

draw_bounding_boxes(gray_images_folder, output_folder_with_boxes)

print(f"Bounding boxes drawn and saved to: {output_folder_with_boxes}")

!pip install ultralytics

from ultralytics import YOLO

# Load a pretrained YOLOv8n model
model = YOLO('yolov8n.pt')  # or yolov8n.yaml

# Run inference on 'Gray_Size' images
results = model.predict(source='/content/drive/MyDrive/Gray_Size', save=True, project='/content/drive/MyDrive/YOLO_Output', name='Gray_Size_Predictions')

# Results are saved to /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions
print("Bounding boxes created and saved in /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions")

import pandas as pd
import os
import cv2
import pytesseract

def extract_text_from_images(yolo_output_folder, csv_output_path):


    data = []
    for filename in os.listdir(yolo_output_folder):
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            image_path = os.path.join(yolo_output_folder, filename)
            img = cv2.imread(image_path)

            # Preprocess the image (e.g., grayscale conversion, noise reduction)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Perform OCR using pytesseract
            extracted_text = pytesseract.image_to_string(gray)

            data.append({'filename': filename, 'extracted_text': extracted_text})

    df = pd.DataFrame(data)
    df.to_csv(csv_output_path, index=False)

# Example usage:
yolo_output_folder = '/content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions'
csv_output_path = '/content/drive/MyDrive/YOLO_Output/extracted_text.csv'
extract_text_from_images(yolo_output_folder, csv_output_path)
print(f"Text extracted and saved to {csv_output_path}")

import cv2
import pytesseract
import os
import pandas as pd

def extract_text_from_images(image_folder, csv_output_path):
    """
    Extracts text from images using Tesseract OCR and saves results to a CSV file.
    """
    data = []
    for filename in os.listdir(image_folder):
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            img = cv2.imread(image_path)

            # Preprocess the image (e.g., grayscale conversion, noise reduction)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Perform OCR using pytesseract
            extracted_text = pytesseract.image_to_string(gray)

            data.append({'filename': filename, 'extracted_text': extracted_text})

    df = pd.DataFrame(data)
    df.to_csv(csv_output_path, index=False)


image_folder_with_boxes = '/content/drive/MyDrive/Train_Model/Gray_Size_Boxes'
csv_output_path = '/content/drive/MyDrive/Train_Model/extracted_text_gray_size_boxes.csv'
extract_text_from_images(image_folder_with_boxes, csv_output_path)
print(f"Text extracted from images with bounding boxes and saved to {csv_output_path}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.feature_extraction.text import TfidfVectorizer

    # Load the extracted features from the CSV file
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')

    # Feature Engineering: Convert text to numerical vectors (Example using word embeddings)
vectorizer = TfidfVectorizer(max_features=1000) # Adjust max_features as needed
text_features = vectorizer.fit_transform(df['extracted_text']).toarray()

    # Reshape the input data for LSTM (samples, timesteps, features)
    # Since we are not using sequential data we set timesteps to 1.
text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])

    # Define the LSTM model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(text_features.shape[1], text_features.shape[2]))) # Adjust units as needed
model.add(Dense(text_features.shape[2])) # Output layer

    # Compile the model
model.compile(optimizer='adam', loss='mse') # Use appropriate loss function

    # Define a checkpoint to save the best model
checkpoint = ModelCheckpoint('/content/drive/MyDrive/best_model.h5', monitor='val_loss', save_best_only=True, mode='min')

    # Train the model
model.fit(text_features, text_features, epochs=10, batch_size=32, validation_split = 0.2, callbacks=[checkpoint])

print("Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5")

import pandas as pd
import numpy as np
import os
import pickle
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint

# === Load the dataset ===
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')  # <-- Adjust path if needed
texts = df['extracted_text'].fillna('')

# === TF-IDF Vectorization ===
vectorizer = TfidfVectorizer(max_features=1000)
text_features = vectorizer.fit_transform(texts).toarray()

# === Reshape for LSTM input: (samples, timesteps=1, features) ===
text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])

# === Define the LSTM Autoencoder Model ===
model = Sequential()
model.add(Input(shape=(1, text_features.shape[2])))  # Use Input() layer (avoid old input_shape keyword)
model.add(LSTM(50, activation='relu'))
model.add(Dense(text_features.shape[2]))  # Output same size as input for reconstruction

model.compile(optimizer='adam', loss='mse')

# === Define save paths ===
model_h5_path = r'/content/drive/MyDrive/Project-10/best_model.h5'
model_saved_path = r'/content/drive/MyDrive/Project-10/best_model_saved'
vectorizer_path = r'/content/drive/MyDrive/Project-10/tfidf_vectorizer.pkl'

# === Define checkpoint for .h5 ===
checkpoint = ModelCheckpoint(model_h5_path, monitor='val_loss', save_best_only=True, mode='min')

# === Train the model ===
model.fit(
    text_features,
    text_features,
    epochs=10,
    batch_size=32,
    validation_split=0.2,
    callbacks=[checkpoint]
)

# === Save model also as TensorFlow SavedModel format ===
model.save(model_saved_path)

# === Save TF-IDF vectorizer ===
with open(vectorizer_path, 'wb') as f:
    pickle.dump(vectorizer, f)

print("Training completed.")
print(f" Best model saved to: {model_h5_path}")
print(f" SavedModel format also saved to: {model_saved_path}")
print(f"Vectorizer saved to: {vectorizer_path}")

from sklearn.metrics import accuracy_score
import numpy as np

# Load the best model
from tensorflow.keras.models import load_model
model = load_model('/content/drive/MyDrive/best_model.h5')

# Load the extracted features from the CSV file
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')

# Feature Engineering: Convert text to numerical vectors (Example using word embeddings)
vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed
text_features = vectorizer.fit_transform(df['extracted_text']).toarray()

# Reshape the input data for LSTM
text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])

# Make predictions
y_pred = model.predict(text_features)

# Assuming y_true is the same as text_features for autoencoder-like setup
y_true = text_features.reshape(text_features.shape[0],text_features.shape[2]) # Reshape to match prediction shape

# Calculate accuracy
# Accuracy is not the best metric for regression or autoencoder-like tasks.
# Consider using Mean Squared Error (MSE) or other relevant metrics.
# Convert predictions to class labels if needed.

# Example using MSE (Mean Squared Error):
mse = np.mean(np.square(y_true - y_pred))
print("Mean Squared Error:", mse)

# Example using accuracy (not the best metric for this setup):
# Find the indices of the maximum value
y_pred_class = np.argmax(y_pred, axis=1)
y_true_class = np.argmax(y_true, axis=1)

accuracy = accuracy_score(y_true_class, y_pred_class)
print("Accuracy:", accuracy)

import pandas as pd

# Load the extracted features from the CSV file
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')

# Check the data types of all columns
print(df.dtypes)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.feature_extraction.text import TfidfVectorizer

# 1. Load and Preprocess Data
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')

# 2. Feature Engineering with TF-IDF (before one-hot encoding)
vectorizer = TfidfVectorizer(max_features=1000)
text_features = vectorizer.fit_transform(df['extracted_text']).toarray()
text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])

# Convert numerical columns to numeric data types
numerical_cols = ['value', 'reference_range']
for col in numerical_cols:
    try:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    except ValueError:
        print(f"WARNING: Could not convert column '{col}' to numeric.")

# Handle missing values (if any) - choose one method
# df.dropna(subset=numerical_cols, inplace=True)  # Remove rows with NaN
# df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())  # Impute with mean

# One-hot encode string columns (excluding 'extracted_text')
string_columns_to_encode = [col for col in df.select_dtypes(include=['object']).columns if col != 'extracted_text']
for col in string_columns_to_encode:
    df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)
    df.drop([col], axis=1, inplace=True)

# 3. Split Data (including text_features)
X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(
    text_features, text_features, test_size=0.2, random_state=42
)

# One-hot encoded data (if needed)
X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(
    df, df, test_size=0.2, random_state=42
)

# 4. Build and Train LSTM Model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(X_train_text.shape[1], X_train_text.shape[2])))
model.add(Dense(X_train_text.shape[2]))

model.compile(optimizer='adam', loss='mse')

checkpoint = ModelCheckpoint(
    '/content/drive/MyDrive/best_model.h5', monitor='val_loss', save_best_only=True, mode='min'
)

model.fit(
    X_train_text,
    y_train_text,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_text, y_test_text),
    callbacks=[checkpoint],
)

print("Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5")

model = load_model('/content/drive/MyDrive/best_model.h5')

# Load the preprocessed data (including one-hot encoded features)
df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')

# 2. Feature Engineering with TF-IDF (before one-hot encoding)
vectorizer = TfidfVectorizer(max_features=1000)
text_features = vectorizer.fit_transform(df['extracted_text']).toarray()
text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])

# Convert numerical columns to numeric data types
numerical_cols = ['value', 'reference_range']
for col in numerical_cols:
    try:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    except ValueError:
        print(f"WARNING: Could not convert column '{col}' to numeric.")

# Handle missing values (if any) - choose one method
# df.dropna(subset=numerical_cols, inplace=True)  # Remove rows with NaN
# df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())  # Impute with mean

# One-hot encode string columns (excluding 'extracted_text')
string_columns_to_encode = [col for col in df.select_dtypes(include=['object']).columns if col != 'extracted_text']
for col in string_columns_to_encode:
    df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)
    df.drop([col], axis=1, inplace=True)

# 3. Split Data (including text_features)
X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(
    text_features, text_features, test_size=0.2, random_state=42
)
# ... (rest of your data loading and preprocessing code)

# Make predictions
y_pred = model.predict(X_test_text)

# Calculate accuracy (adjust as needed)
mse = np.mean(np.square(y_test_text.reshape(y_test_text.shape[0],y_test_text.shape[2]) - y_pred))
print("Mean Squared Error:", mse)

# You can also try to calculate an accuracy like this:
# Accuracy is not the best metric for regression or autoencoder-like tasks.
# Consider using Mean Squared Error (MSE) or other relevant metrics.
y_pred_class = np.argmax(y_pred, axis=1)
y_true_class = np.argmax(y_test_text.reshape(y_test_text.shape[0], y_test_text.shape[2]), axis=1)

accuracy = accuracy_score(y_true_class, y_pred_class)
print("Accuracy:", accuracy)

import pickle

# Assuming 'model' is your trained LSTM model
# Save the model to a pickle file
with open('/content/drive/MyDrive/trained_model.pkl', 'wb') as f:
    pickle.dump(model, f)

print("Model saved to /content/drive/MyDrive/trained_model.pkl")